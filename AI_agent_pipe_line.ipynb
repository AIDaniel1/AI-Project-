{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwf9TUYq/z/gAPHWIlA8K9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AIDaniel1/AI-Project-/blob/main/AI_agent_pipe_line.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ai_agent_pipeline.py\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_requirements():\n",
        "    \"\"\"Install required packages\"\"\"\n",
        "    packages = [\n",
        "        \"chromadb\", \"langchain-openai\", \"openai\", \"fastapi\",\n",
        "        \"uvicorn\", \"streamlit\", \"python-dotenv\", \"requests\",\n",
        "        \"sentence-transformers\", \"nest-asyncio\"\n",
        "    ]\n",
        "\n",
        "    for package in packages:\n",
        "        try:\n",
        "            __import__(package.replace(\"-\", \"_\"))\n",
        "            print(f\"‚úÖ {package} already installed\")\n",
        "        except ImportError:\n",
        "            print(f\"üì¶ Installing {package}...\")\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "# Install dependencies first\n",
        "install_requirements()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvfnJXdmyt9i",
        "outputId": "9d073a6a-3e83-40d0-e1e7-5111cefc8a00"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Installing chromadb...\n",
            "üì¶ Installing langchain-openai...\n",
            "‚úÖ openai already installed\n",
            "‚úÖ fastapi already installed\n",
            "‚úÖ uvicorn already installed\n",
            "üì¶ Installing streamlit...\n",
            "üì¶ Installing python-dotenv...\n",
            "‚úÖ requests already installed\n",
            "‚úÖ sentence-transformers already installed\n",
            "‚úÖ nest-asyncio already installed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5q2nAxr7s5ne"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "import uuid\n",
        "from typing import List, Dict, Any\n",
        "import os\n",
        "\n",
        "class VectorDatabase:\n",
        "    def __init__(self, persist_directory=\"./chroma_db\"):\n",
        "        try:\n",
        "            # Create directory if it doesn't exist\n",
        "            os.makedirs(persist_directory, exist_ok=True)\n",
        "\n",
        "            self.client = chromadb.PersistentClient(path=persist_directory)\n",
        "            self.collection = self.client.get_or_create_collection(\n",
        "                name=\"knowledge_base\",\n",
        "                metadata={\"description\": \"AI Agent Knowledge Base\"}\n",
        "            )\n",
        "            print(\"‚úÖ Vector database initialized successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error initializing vector database: {e}\")\n",
        "            raise\n",
        "\n",
        "    def add_documents(self, documents: List[str], metadatas: List[Dict] = None, ids: List[str] = None):\n",
        "        \"\"\"Add documents to the vector database\"\"\"\n",
        "        try:\n",
        "            if ids is None:\n",
        "                ids = [str(uuid.uuid4()) for _ in documents]\n",
        "\n",
        "            if metadatas is None:\n",
        "                metadatas = [{} for _ in documents]\n",
        "\n",
        "            self.collection.add(\n",
        "                documents=documents,\n",
        "                metadatas=metadatas,\n",
        "                ids=ids\n",
        "            )\n",
        "            print(f\"‚úÖ Added {len(documents)} documents to vector database\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error adding documents: {e}\")\n",
        "            raise\n",
        "\n",
        "    def search(self, query: str, n_results: int = 3) -> List[Dict]:\n",
        "        \"\"\"Search for similar documents\"\"\"\n",
        "        try:\n",
        "            results = self.collection.query(\n",
        "                query_texts=[query],\n",
        "                n_results=n_results\n",
        "            )\n",
        "\n",
        "            formatted_results = []\n",
        "            for i in range(len(results['documents'][0])):\n",
        "                formatted_results.append({\n",
        "                    \"document\": results['documents'][0][i],\n",
        "                    \"metadata\": results['metadatas'][0][i] if results['metadatas'] else {},\n",
        "                    \"distance\": results['distances'][0][i] if results['distances'] else 0\n",
        "                })\n",
        "\n",
        "            return formatted_results\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error searching vector database: {e}\")\n",
        "            return []\n",
        "\n",
        "    def get_all_documents(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get all documents from the collection\"\"\"\n",
        "        try:\n",
        "            return self.collection.get()\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error getting all documents: {e}\")\n",
        "            return {'ids': [], 'documents': [], 'metadatas': []}\n",
        "\n",
        "def initialize_sample_data():\n",
        "    \"\"\"Initialize with sample data\"\"\"\n",
        "    db = VectorDatabase()\n",
        "\n",
        "    # Check if collection is empty\n",
        "    existing_docs = db.get_all_documents()\n",
        "    if len(existing_docs['ids']) > 0:\n",
        "        print(\"‚úÖ Sample data already exists\")\n",
        "        return db\n",
        "\n",
        "    sample_documents = [\n",
        "        \"Machine learning is a subset of artificial intelligence that enables computers to learn without being explicitly programmed.\",\n",
        "        \"Natural Language Processing (NLP) is a field of AI that focuses on the interaction between computers and human language.\",\n",
        "        \"Vector databases store data as high-dimensional vectors and enable efficient similarity search.\",\n",
        "        \"Large Language Models (LLMs) are AI models trained on vast amounts of text data to understand and generate human-like text.\",\n",
        "        \"Retrieval-Augmented Generation (RAG) combines retrieval systems with generative models for more accurate responses.\",\n",
        "        \"AI agents are autonomous systems that can perceive, reason, and act to achieve specific goals.\"\n",
        "    ]\n",
        "\n",
        "    sample_metadata = [\n",
        "        {\"category\": \"ML\", \"source\": \"knowledge_base\"},\n",
        "        {\"category\": \"NLP\", \"source\": \"knowledge_base\"},\n",
        "        {\"category\": \"Database\", \"source\": \"knowledge_base\"},\n",
        "        {\"category\": \"LLM\", \"source\": \"knowledge_base\"},\n",
        "        {\"category\": \"RAG\", \"source\": \"knowledge_base\"},\n",
        "        {\"category\": \"Agents\", \"source\": \"knowledge_base\"}\n",
        "    ]\n",
        "\n",
        "    db.add_documents(sample_documents, sample_metadata)\n",
        "    print(\"‚úÖ Sample data initialized\")\n",
        "    return db"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from typing import List, Dict\n",
        "import requests\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "class LLMIntegration:\n",
        "    def __init__(self, api_key: str = None, model: str = \"gpt-3.5-turbo\"):\n",
        "        try:\n",
        "            self.api_key = api_key or os.getenv(\"OPENAI_API_KEY\")\n",
        "            if not self.api_key:\n",
        "                raise ValueError(\"OpenAI API key not found. Please set OPENAI_API_KEY environment variable.\")\n",
        "\n",
        "            self.client = OpenAI(api_key=self.api_key)\n",
        "            self.model = model\n",
        "            print(\"‚úÖ LLM integration initialized successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error initializing LLM integration: {e}\")\n",
        "            raise\n",
        "\n",
        "    def generate_response(self, prompt: str, context: str = \"\", conversation_history: List[Dict] = None) -> str:\n",
        "        \"\"\"Generate response using LLM with context\"\"\"\n",
        "        try:\n",
        "            system_message = \"\"\"You are an AI assistant with access to a knowledge base.\n",
        "            Use the provided context to answer questions accurately. If the context doesn't\n",
        "            contain relevant information, use your general knowledge but indicate this.\"\"\"\n",
        "\n",
        "            messages = [{\"role\": \"system\", \"content\": system_message}]\n",
        "\n",
        "            # Add conversation history if provided\n",
        "            if conversation_history:\n",
        "                messages.extend(conversation_history[-6:])  # Keep last 3 exchanges\n",
        "\n",
        "            # Add context if available\n",
        "            if context:\n",
        "                enhanced_prompt = f\"Context:\\n{context}\\n\\nQuestion: {prompt}\\n\\nPlease provide a helpful answer based on the context above.\"\n",
        "            else:\n",
        "                enhanced_prompt = f\"Question: {prompt}\\n\\nPlease provide a helpful answer.\"\n",
        "\n",
        "            messages.append({\"role\": \"user\", \"content\": enhanced_prompt})\n",
        "\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=messages,\n",
        "                temperature=0.7,\n",
        "                max_tokens=500\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            return f\"I apologize, but I encountered an error: {str(e)}. Please check your API key and try again.\"\n",
        "\n",
        "    def format_context(self, search_results: List[Dict]) -> str:\n",
        "        \"\"\"Format search results into context string\"\"\"\n",
        "        if not search_results:\n",
        "            return \"No relevant context found.\"\n",
        "\n",
        "        context_parts = [\"Relevant information from knowledge base:\"]\n",
        "        for i, result in enumerate(search_results, 1):\n",
        "            context_parts.append(f\"{i}. {result['document']}\")\n",
        "\n",
        "        return \"\\n\".join(context_parts)\n",
        "\n",
        "# Fallback LLM class for testing without API key\n",
        "class MockLLMIntegration:\n",
        "    def __init__(self):\n",
        "        print(\"‚úÖ Mock LLM integration initialized (for testing)\")\n",
        "\n",
        "    def generate_response(self, prompt: str, context: str = \"\", conversation_history: List[Dict] = None) -> str:\n",
        "        return f\"This is a mock response for: '{prompt}'. Context provided: {len(context) if context else 0} characters.\"\n",
        "\n",
        "    def format_context(self, search_results: List[Dict]) -> str:\n",
        "        return \"Mock context with \" + str(len(search_results)) + \" search results\""
      ],
      "metadata": {
        "id": "ubjdbTRQwoNm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main.py\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Optional\n",
        "import uvicorn\n",
        "\n",
        "app = FastAPI(title=\"AI Agent Pipeline API\")\n",
        "\n",
        "# CORS middleware\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# Initialize components\n",
        "vector_db = VectorDatabase()\n",
        "llm = LLMIntegration()\n",
        "agent = AIAgentPipeline(vector_db, llm)\n",
        "\n",
        "# Request/Response models\n",
        "class QueryRequest(BaseModel):\n",
        "    message: str\n",
        "    use_rag: bool = True\n",
        "\n",
        "class QueryResponse(BaseModel):\n",
        "    response: str\n",
        "    context_used: str\n",
        "    search_results: List[Dict]\n",
        "    conversation_turn: int\n",
        "\n",
        "class AddKnowledgeRequest(BaseModel):\n",
        "    documents: List[str]\n",
        "    metadatas: Optional[List[Dict]] = None\n",
        "\n",
        "@app.post(\"/query\", response_model=QueryResponse)\n",
        "async def process_query(request: QueryRequest):\n",
        "    \"\"\"Process user query through AI agent pipeline\"\"\"\n",
        "    try:\n",
        "        result = agent.process_query(request.message, request.use_rag)\n",
        "        return QueryResponse(**result)\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.post(\"/knowledge/add\")\n",
        "async def add_knowledge(request: AddKnowledgeRequest):\n",
        "    \"\"\"Add new knowledge to the vector database\"\"\"\n",
        "    try:\n",
        "        agent.add_knowledge(request.documents, request.metadatas)\n",
        "        return {\"message\": \"Knowledge added successfully\"}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.post(\"/conversation/clear\")\n",
        "async def clear_conversation():\n",
        "    \"\"\"Clear conversation history\"\"\"\n",
        "    agent.clear_history()\n",
        "    return {\"message\": \"Conversation history cleared\"}\n",
        "\n",
        "@app.get(\"/stats\")\n",
        "async def get_stats():\n",
        "    \"\"\"Get pipeline statistics\"\"\"\n",
        "    return agent.get_stats()\n",
        "\n",
        "@app.get(\"/health\")\n",
        "async def health_check():\n",
        "    \"\"\"Health check endpoint\"\"\"\n",
        "    return {\"status\": \"healthy\", \"service\": \"AI Agent Pipeline API\"}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "NlZH6xr3wuEo",
        "outputId": "a3890a91-0d33-454f-b3af-3f25597ece4a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Vector database initialized successfully\n",
            "‚ùå Error initializing LLM integration: OpenAI API key not found. Please set OPENAI_API_KEY environment variable.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "OpenAI API key not found. Please set OPENAI_API_KEY environment variable.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3531568631.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Initialize components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mvector_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectorDatabase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLMIntegration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAIAgentPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_db\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3686938491.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, model)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OpenAI API key not found. Please set OPENAI_API_KEY environment variable.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: OpenAI API key not found. Please set OPENAI_API_KEY environment variable."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "import streamlit as st\n",
        "import requests\n",
        "import json\n",
        "from typing import List, Dict\n",
        "\n",
        "# Configuration\n",
        "API_BASE_URL = \"http://localhost:8000\"\n",
        "\n",
        "def initialize_session_state():\n",
        "    \"\"\"Initialize session state variables\"\"\"\n",
        "    if \"messages\" not in st.session_state:\n",
        "        st.session_state.messages = []\n",
        "    if \"use_rag\" not in st.session_state:\n",
        "        st.session_state.use_rag = True\n",
        "\n",
        "def call_api(endpoint: str, method: str = \"GET\", data: Dict = None):\n",
        "    \"\"\"Make API call to backend\"\"\"\n",
        "    url = f\"{API_BASE_URL}{endpoint}\"\n",
        "\n",
        "    try:\n",
        "        if method == \"GET\":\n",
        "            response = requests.get(url)\n",
        "        elif method == \"POST\":\n",
        "            response = requests.post(url, json=data)\n",
        "\n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        st.error(f\"API Error: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    st.set_page_config(\n",
        "        page_title=\"AI Agent Pipeline\",\n",
        "        page_icon=\"ü§ñ\",\n",
        "        layout=\"wide\"\n",
        "    )\n",
        "\n",
        "    st.title(\"ü§ñ AI Agent Pipeline\")\n",
        "    st.markdown(\"Chat with your AI agent powered by Vector Database and LLM\")\n",
        "\n",
        "    initialize_session_state()\n",
        "\n",
        "    # Sidebar for configuration\n",
        "    with st.sidebar:\n",
        "        st.header(\"Configuration\")\n",
        "\n",
        "        # RAG toggle\n",
        "        st.session_state.use_rag = st.toggle(\n",
        "            \"Use RAG (Retrieval-Augmented Generation)\",\n",
        "            value=st.session_state.use_rag\n",
        "        )\n",
        "\n",
        "        # Add knowledge section\n",
        "        st.subheader(\"Add Knowledge\")\n",
        "        with st.form(\"add_knowledge\"):\n",
        "            new_doc = st.text_area(\"New Document\")\n",
        "            doc_category = st.text_input(\"Category\")\n",
        "\n",
        "            if st.form_submit_button(\"Add to Knowledge Base\"):\n",
        "                if new_doc:\n",
        "                    metadata = {\"category\": doc_category} if doc_category else {}\n",
        "                    result = call_api(\n",
        "                        \"/knowledge/add\",\n",
        "                        \"POST\",\n",
        "                        {\"documents\": [new_doc], \"metadatas\": [metadata]}\n",
        "                    )\n",
        "                    if result:\n",
        "                        st.success(\"Document added to knowledge base!\")\n",
        "\n",
        "        # Stats and controls\n",
        "        st.subheader(\"System Info\")\n",
        "        if st.button(\"Get Statistics\"):\n",
        "            stats = call_api(\"/stats\")\n",
        "            if stats:\n",
        "                st.json(stats)\n",
        "\n",
        "        if st.button(\"Clear Conversation\"):\n",
        "            call_api(\"/conversation/clear\", \"POST\")\n",
        "            st.session_state.messages = []\n",
        "            st.rerun()\n",
        "\n",
        "    # Main chat interface\n",
        "    col1, col2 = st.columns([3, 1])\n",
        "\n",
        "    with col1:\n",
        "        # Display chat messages\n",
        "        for message in st.session_state.messages:\n",
        "            with st.chat_message(message[\"role\"]):\n",
        "                st.markdown(message[\"content\"])\n",
        "\n",
        "                # Show context if available and RAG is enabled\n",
        "                if message.get(\"context\") and st.session_state.use_rag:\n",
        "                    with st.expander(\"üìö Context Used\"):\n",
        "                        st.text(message[\"context\"])\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"Pipeline Flow\")\n",
        "        st.markdown(\"\"\"\n",
        "        ```\n",
        "        User Query\n",
        "            ‚Üì\n",
        "        Vector DB Search\n",
        "            ‚Üì\n",
        "        Context + Query\n",
        "            ‚Üì\n",
        "        LLM Processing\n",
        "            ‚Üì\n",
        "        Response\n",
        "        ```\n",
        "        \"\"\")\n",
        "\n",
        "        if st.session_state.messages:\n",
        "            latest_message = st.session_state.messages[-1]\n",
        "            if latest_message.get(\"search_results\"):\n",
        "                st.subheader(\"Search Results\")\n",
        "                for i, result in enumerate(latest_message[\"search_results\"][:3]):\n",
        "                    with st.expander(f\"Result {i+1}\"):\n",
        "                        st.text(result[\"document\"][:100] + \"...\")\n",
        "\n",
        "    # Chat input\n",
        "    if prompt := st.chat_input(\"What would you like to know?\"):\n",
        "        # Add user message to chat history\n",
        "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.markdown(prompt)\n",
        "\n",
        "        # Get AI response\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            with st.spinner(\"Thinking...\"):\n",
        "                result = call_api(\n",
        "                    \"/query\",\n",
        "                    \"POST\",\n",
        "                    {\"message\": prompt, \"use_rag\": st.session_state.use_rag}\n",
        "                )\n",
        "\n",
        "                if result:\n",
        "                    response = result[\"response\"]\n",
        "                    st.markdown(response)\n",
        "\n",
        "                    # Add assistant response with context to history\n",
        "                    st.session_state.messages.append({\n",
        "                        \"role\": \"assistant\",\n",
        "                        \"content\": response,\n",
        "                        \"context\": result.get(\"context_used\", \"\"),\n",
        "                        \"search_results\": result.get(\"search_results\", [])\n",
        "                    })\n",
        "                else:\n",
        "                    st.error(\"Failed to get response from AI agent\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRw-pKLPxbeF",
        "outputId": "6e7c225e-0a07-4c4b-9da4-3b94ac7d9018"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-11-08 23:30:10.601 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.602 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.813 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-11-08 23:30:10.813 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.814 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.815 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.816 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.817 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.817 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.819 Session state does not function when running a script without `streamlit run`\n",
            "2025-11-08 23:30:10.820 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.821 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.821 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.822 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.823 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.824 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.825 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.827 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.828 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.829 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.830 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.831 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.832 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.833 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.834 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.836 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.837 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.839 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.840 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.841 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.843 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.844 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.845 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.849 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.850 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.853 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.854 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.855 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.857 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.857 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.859 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.859 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.860 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.861 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.862 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.863 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.866 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.867 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.869 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.869 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.870 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.871 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.873 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.873 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.874 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.877 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.877 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.878 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.879 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.879 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.880 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.881 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.881 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.882 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.884 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.884 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.885 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.886 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.886 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.888 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.888 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.889 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.890 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.890 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.891 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.892 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.893 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.894 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.896 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.896 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.896 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.897 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.899 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-08 23:30:10.900 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    }
  ]
}